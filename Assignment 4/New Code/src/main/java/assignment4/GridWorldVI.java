package assignment4;

import burlap.behavior.policy.Policy;
import javax.imageio.ImageIO;
import java.awt.image.BufferedImage;
import java.io.File;
import java.io.IOException;

import burlap.behavior.singleagent.EpisodeAnalysis;
import burlap.behavior.singleagent.auxiliary.StateReachability;
import burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUI;
import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;
import burlap.domain.singleagent.gridworld.GridWorldDomain;
import burlap.domain.singleagent.gridworld.GridWorldTerminalFunction;
import burlap.oomdp.auxiliary.stateconditiontest.TFGoalCondition;
import burlap.oomdp.core.Domain;
import burlap.oomdp.core.TerminalFunction;
import burlap.oomdp.core.states.State;
import burlap.oomdp.singleagent.RewardFunction;
import burlap.oomdp.singleagent.SADomain;
import burlap.oomdp.singleagent.common.GoalBasedRF;
import burlap.oomdp.singleagent.common.UniformCostRF;
import burlap.oomdp.singleagent.environment.SimulatedEnvironment;
import burlap.oomdp.singleagent.explorer.VisualExplorer;
import burlap.oomdp.statehashing.SimpleHashableStateFactory;
import burlap.oomdp.visualizer.StateRenderLayer;
import burlap.oomdp.visualizer.Visualizer;

import java.util.List;
import java.util.Scanner;

import assignment4.util.AgentPainter;
import assignment4.util.LocationPainter;
import assignment4.util.WallPainter;

public class GridWorldVI{
    public static void main(String [] args) throws IOException{
        Scanner reader = new Scanner(System.in);
        String CLASSAGENT = "agent";
    	String CLASSLOCATION = "location";

        System.out.println("What domain is tested?\n1. 11 cells\n2. Four Rooms\n3. Maze");
        GridWorldDomain gwd = new GridWorldDomain(11, 11);
        gwd.setMapToFourRooms();

        //terminate in top right corner
        TerminalFunction tf = new GridWorldTerminalFunction(10, 10);
        int agentX = 0, agentY = 0;
        int[][] map = null;
        String header = null;

        switch (reader.nextInt()) {
            case 1:
            	header = "singleBlock";
            	map = new int[][] {
                        {0,0,0},
                        {0,1,0},
                        {0,1,0},
                        {0,0,0},
            	};
                gwd = new GridWorldDomain(map);
                tf = new GridWorldTerminalFunction(3,2);
                break;
            case 2:
            	header = "fourRooms";
                gwd = new GridWorldDomain(11, 11);
                map = new int[][]{
            		{0,0,0,0,0,1,0,0,0,0,0},
            		{0,0,0,0,0,0,0,0,0,0,0},
            		{0,0,0,0,0,1,0,0,0,0,0},
            		{0,0,0,0,0,1,0,0,0,0,0},
            		{0,0,0,0,0,1,0,0,0,0,0},
            		{1,0,1,1,1,1,1,1,0,1,1},
            		{0,0,0,0,1,0,0,0,0,0,0},
            		{0,0,0,0,1,0,0,0,0,0,0},
            		{0,0,0,0,0,0,0,0,0,0,0},
            		{0,0,0,0,1,0,0,0,0,0,0},
            		{0,0,0,0,1,0,0,0,0,0,0},};
                gwd.setMapToFourRooms();
                break;
            case 3:
            	header = "maze";
            	map = new int[][]{
                        {0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
                        {0,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1},
                        {0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
                        {1,1,0,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1},
                        {0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1},
                        {0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,1,0,1},
                        {0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,1},
                        {1,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1},
                        {0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,1},
                        {0,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1},
                        {0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1},
                        {0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1},
                        {0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1},
                        {0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,1},
                        {0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,1},
                        {1,1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1},
                        {0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1},
                        {0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,0,1},
                        {0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,1},
                        {0,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,0,1,1,1,0,1,0,1},
                        {0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,1},
                        {1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1},
                        {0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1},
                        {0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1},
                        {0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,1},
                        {0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,1,1},
                        {0,0,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,1},
                        {1,1,0,1,0,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,1,0,1,1,1,0,1},
                        {0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,1},
                        {0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,0,1,1,1},
                        {0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1},
                        {1,1,0,1,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,1,1},
                        {0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,1},
                        {0,1,0,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1},
                        {0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,1},
                        {0,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1},
                        {0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,0,0,1,0,1},
                        {1,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1},
                        {0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,1},
                        {0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1},
                    };
                gwd = new GridWorldDomain(map);
                tf = new GridWorldTerminalFunction(0, 38);
                agentX = 39;
                agentY = 0;
                break;
        }

        System.out.println("What's the termination reward?");
        final double tr = reader.nextDouble();

        System.out.println("What's the step reward?");
        final double sr = reader.nextDouble();

        System.out.println("What is the discount?");
        final double dc = reader.nextDouble();

        //only go in intended directon 80% of the time
        gwd.setProbSucceedTransitionDynamics(0.8);

        Domain domain = gwd.generateDomain();

        //get initial state with agent in 0,0
        State s = GridWorldDomain.getOneAgentNoLocationState(domain);
        GridWorldDomain.setAgent(s, agentX, agentY);

        //all transitions return -1
        RewardFunction rf = new GoalBasedRF(new TFGoalCondition(tf), tr, sr);
        
      //initial view of GridWorld Domain
        SimulatedEnvironment env = new SimulatedEnvironment(domain, rf, tf,
				s);
//        Visualizer v = new Visualizer(getStateRenderLayer(map,CLASSLOCATION,CLASSAGENT));
//        VisualExplorer exp = new VisualExplorer(domain, env, v);

//		exp.setTitle("Easy Grid World");
//		exp.initGUI();

        final long startTime = System.currentTimeMillis();
        //setup vi with 0.99 discount factor, a value
        //function initialization that initializes all states to value 0, and which will
        //run for 30 iterations over the state space
        ValueIteration vi = new ValueIteration(domain, rf, tf, dc, new SimpleHashableStateFactory(),
               0.01, 100000);
        //run planning from our initial state
        Policy p = vi.planFromState(s);
        final long endTime = System.currentTimeMillis();
        EpisodeAnalysis ea = p.evaluateBehavior(s, rf, tf, 100000);
        
        double sum = 0;
        for(Double r : ea.rewardSequence) {
            sum += r;
        }
        System.out.println("Steps taken to exit: " + ea.actionSequence.size());
        System.out.println("Runtime: " + (endTime - startTime) + " milliseconds");
        System.out.println("Total Reward: " + sum);

        
        
        //new EpisodeSequenceVisualizer(v, domain, Arrays.asList(ea));
//        List<State> allStates = StateReachability.getReachableStates(s,
//                (SADomain) domain, new SimpleHashableStateFactory());
//
//        ValueFunctionVisualizerGUI gui = GridWorldDomain.getGridWorldValueFunctionVisualization(
//                allStates, vi, p);
//        gui.initGUI();

//        
        

    }
    
    public static StateRenderLayer getStateRenderLayer(int[][] map, String CLASSLOCATION, String CLASSAGENT ) {
		StateRenderLayer rl = new StateRenderLayer();
		rl.addStaticPainter(new WallPainter(map));
		rl.addObjectClassPainter(CLASSLOCATION, new LocationPainter(map));
		rl.addObjectClassPainter(CLASSAGENT, new AgentPainter(map));
		return rl;
	}

}
